{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e15bfdf-9dc4-4476-8790-a0ad4b2645c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection results saved to output_with_detections.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Set logging level to WARNING to reduce output\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load a pretrained YOLO model (make sure \"best.pt\" exists in your working directory)\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# Function to detect potholes in an image and save/display the result\n",
    "def detect_potholes(image_path, output_path=\"output_with_detections.jpg\", conf_threshold=0.55):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image from {image_path}. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    # Perform inference\n",
    "    results = model(img)\n",
    "\n",
    "    # Define colors for bounding box and text\n",
    "    box_color = (255, 0, 0)  # Blue box\n",
    "    text_color = (255, 255, 255)  # White text\n",
    "\n",
    "    # Process results\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Get bounding boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].numpy().astype(int)  # Get coordinates of bounding box\n",
    "            confidence = box.conf[0].item()  # Get confidence score\n",
    "            \n",
    "            # Filter detections by confidence threshold\n",
    "            if confidence > conf_threshold:\n",
    "                # Draw bounding box and label\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)\n",
    "                cv2.putText(img, f'Pothole {confidence:.2f}', (x1, y1 - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 2)\n",
    "\n",
    "    # Display the image with detected potholes\n",
    "    cv2.imshow(\"Detected Potholes\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the image with detections\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"Detection results saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = r\"D:\\Myproject\\Pothole Dataset\\img-347.jpg\"  # Update with your image path\n",
    "detect_potholes(new_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4a53e2c-9f08-44c4-bd81-3ae950120501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to output_with_detections.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Set logging level to WARNING to reduce output\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load a pretrained YOLO model (make sure \"best.pt\" exists in your working directory)\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# IoU calculation function\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_t, y1_t, x2_t, y2_t = box2\n",
    "    \n",
    "    # Calculate the coordinates of the intersection rectangle\n",
    "    ix1 = max(x1, x1_t)\n",
    "    iy1 = max(y1, y1_t)\n",
    "    ix2 = min(x2, x2_t)\n",
    "    iy2 = min(y2, y2_t)\n",
    "\n",
    "    # Check if there is an intersection\n",
    "    inter_area = max(0, ix2 - ix1) * max(0, iy2 - iy1)\n",
    "    \n",
    "    # Calculate areas\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2_t - x1_t) * (y2_t - y1_t)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area if union_area > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# Function to load ground truth annotations from a text file\n",
    "def load_ground_truth(txt_file, img_width, img_height):\n",
    "    gt_boxes = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            \n",
    "            # Convert normalized coordinates to pixel values\n",
    "            x1 = int((x_center - width / 2) * img_width)\n",
    "            y1 = int((y_center - height / 2) * img_height)\n",
    "            x2 = int((x_center + width / 2) * img_width)\n",
    "            y2 = int((y_center + height / 2) * img_height)\n",
    "            \n",
    "            gt_boxes.append([x1, y1, x2, y2])\n",
    "    return gt_boxes\n",
    "\n",
    "# Function to detect potholes in an image and analyze performance\n",
    "def detect_potholes_and_evaluate(image_path, annotation_path, output_path=\"output_with_detections.jpg\", conf_threshold=0.55):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image from {image_path}. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    # Get image dimensions\n",
    "    img_height, img_width, _ = img.shape\n",
    "    \n",
    "    # Load ground truth annotations from the text file\n",
    "    ground_truth_boxes = load_ground_truth(annotation_path, img_width, img_height)\n",
    "\n",
    "    # Perform inference\n",
    "    results = model(img)\n",
    "    \n",
    "    # Initialize lists for true positives, false positives, false negatives\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    # Define colors for bounding box and text\n",
    "    box_color = (255, 0, 0)  # Blue box\n",
    "    text_color = (255, 255, 255)  # White text\n",
    "\n",
    "    detected_boxes = []\n",
    "\n",
    "    # Process results\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Get bounding boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].numpy().astype(int)  # Get coordinates of bounding box\n",
    "            confidence = box.conf[0].item()  # Get confidence score\n",
    "            \n",
    "            # Filter detections by confidence threshold\n",
    "            if confidence > conf_threshold:\n",
    "                detected_boxes.append([x1, y1, x2, y2])\n",
    "                \n",
    "                # Draw bounding box and label\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)\n",
    "                cv2.putText(img, f'Pothole {confidence:.2f}', (x1, y1 - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 2)\n",
    "    \n",
    "    # Compare detected boxes with ground truth\n",
    "    for gt_box in ground_truth_boxes:\n",
    "        matched = False\n",
    "        for det_box in detected_boxes:\n",
    "            if iou(gt_box, det_box) > 0.5:  # If IoU > 0.5, consider it a match\n",
    "                tp += 1\n",
    "                matched = True\n",
    "                detected_boxes.remove(det_box)\n",
    "                break\n",
    "        if not matched:\n",
    "            fn += 1\n",
    "\n",
    "    # Any remaining detected boxes are false positives\n",
    "    fp += len(detected_boxes)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    total_gt_boxes = len(ground_truth_boxes)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Display the evaluation metrics\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "\n",
    "    # Display the image with detected potholes\n",
    "    cv2.imshow(\"Detected Potholes\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the image with detections\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"Detection results saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = r\"D:\\Myproject\\Pothole Dataset\\img-1071.jpg\"  # Update with your image path\n",
    "annotation_file = r\"D:\\Myproject\\Pothole Dataset\\img-1071.txt\"  # Update with your annotation file path\n",
    "detect_potholes_and_evaluate(new_image_path, annotation_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f10965b-50a2-4602-a3c7-6c92abba43e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00\n",
      "Recall: 0.75\n",
      "F1-score: 0.86\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1034_output.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Set logging level to WARNING to reduce output\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load a pretrained YOLO model (make sure \"best.pt\" exists in your working directory)\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# IoU calculation function\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_t, y1_t, x2_t, y2_t = box2\n",
    "    \n",
    "    # Calculate the coordinates of the intersection rectangle\n",
    "    ix1 = max(x1, x1_t)\n",
    "    iy1 = max(y1, y1_t)\n",
    "    ix2 = min(x2, x2_t)\n",
    "    iy2 = min(y2, y2_t)\n",
    "\n",
    "    # Check if there is an intersection\n",
    "    inter_area = max(0, ix2 - ix1) * max(0, iy2 - iy1)\n",
    "    \n",
    "    # Calculate areas\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2_t - x1_t) * (y2_t - y1_t)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area if union_area > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# Function to load ground truth annotations from a text file\n",
    "def load_ground_truth(txt_file, img_width, img_height):\n",
    "    gt_boxes = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            \n",
    "            # Convert normalized coordinates to pixel values\n",
    "            x1 = int((x_center - width / 2) * img_width)\n",
    "            y1 = int((y_center - height / 2) * img_height)\n",
    "            x2 = int((x_center + width / 2) * img_width)\n",
    "            y2 = int((y_center + height / 2) * img_height)\n",
    "            \n",
    "            gt_boxes.append([x1, y1, x2, y2])\n",
    "    return gt_boxes\n",
    "\n",
    "# Function to detect potholes in an image and analyze performance\n",
    "def detect_potholes_and_evaluate(image_path, annotation_path, output_path=\"output_with_detections.jpg\", conf_threshold=0.55):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image from {image_path}. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    # Get image dimensions\n",
    "    img_height, img_width, _ = img.shape\n",
    "    \n",
    "    # Load ground truth annotations from the text file\n",
    "    ground_truth_boxes = load_ground_truth(annotation_path, img_width, img_height)\n",
    "\n",
    "    # Perform inference\n",
    "    results = model(img)\n",
    "    \n",
    "    # Initialize lists for true positives, false positives, false negatives\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    # Define colors for bounding box and text\n",
    "    box_color = (255, 0, 0)  # Blue box\n",
    "    text_color = (255, 255, 255)  # White text\n",
    "\n",
    "    detected_boxes = []\n",
    "\n",
    "    # Process results\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Get bounding boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].numpy().astype(int)  # Get coordinates of bounding box\n",
    "            confidence = box.conf[0].item()  # Get confidence score\n",
    "            \n",
    "            # Filter detections by confidence threshold\n",
    "            if confidence > conf_threshold:\n",
    "                detected_boxes.append([x1, y1, x2, y2])\n",
    "                \n",
    "                # Draw bounding box and label\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)\n",
    "                cv2.putText(img, f'Pothole {confidence:.2f}', (x1, y1 - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 2)\n",
    "    \n",
    "    # Compare detected boxes with ground truth\n",
    "    for gt_box in ground_truth_boxes:\n",
    "        matched = False\n",
    "        for det_box in detected_boxes:\n",
    "            if iou(gt_box, det_box) > 0.4:  # If IoU > 0.5, consider it a match\n",
    "                tp += 1\n",
    "                matched = True\n",
    "                detected_boxes.remove(det_box)\n",
    "                break\n",
    "        if not matched:\n",
    "            fn += 1\n",
    "\n",
    "    # Any remaining detected boxes are false positives\n",
    "    fp += len(detected_boxes)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    total_gt_boxes = len(ground_truth_boxes)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Display the evaluation metrics\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "\n",
    "    # Display the image with detected potholes\n",
    "    cv2.imshow(\"Detected Potholes\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the image with detections\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"Detection results saved to {output_path}\")\n",
    "\n",
    "# Example usage: Process a single image and its corresponding annotation file\n",
    "def process_single_image(image_path, annotation_path, output_dir):\n",
    "    # Check if the output directory exists, otherwise create it\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Extract the image name without the extension\n",
    "    image_name = os.path.basename(image_path).split('.')[0]\n",
    "    output_image_path = os.path.join(output_dir, f\"{image_name}_output.jpg\")\n",
    "\n",
    "    # Call the function to detect potholes and evaluate performance\n",
    "    detect_potholes_and_evaluate(image_path, annotation_path, output_path=output_image_path)\n",
    "\n",
    "# Example usage: Input image and label path\n",
    "image_path = r\"D:\\Myproject\\Pothole Dataset\\img-1034.jpg\"  # Path to your input image\n",
    "annotation_path = r\"D:\\Myproject\\Pothole Dataset\\img-1034.txt\"  # Path to the corresponding annotation file\n",
    "output_dir = r\"D:\\Myproject\\Pothole Dataset\\outputs\"  # Output directory to save the result\n",
    "\n",
    "# Process the single image and its label\n",
    "process_single_image(image_path, annotation_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "973c8d83-1378-4c03-a1b8-527aad331dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation file not found for blackedge.jpg, skipping...\n",
      "Processing img-1.jpg (2/25)\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-score: 0.67\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1_output.jpg\n",
      "Processing img-10.jpg (3/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-10_output.jpg\n",
      "Processing img-100.jpg (4/25)\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-score: 0.67\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-100_output.jpg\n",
      "Processing img-1000.jpg (5/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.67\n",
      "F1-score: 0.80\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1000_output.jpg\n",
      "Processing img-1001.jpg (6/25)\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1001_output.jpg\n",
      "Processing img-1002.jpg (7/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.18\n",
      "F1-score: 0.30\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1002_output.jpg\n",
      "Processing img-1003.jpg (8/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.33\n",
      "F1-score: 0.50\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1003_output.jpg\n",
      "Processing img-1004.jpg (9/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1004_output.jpg\n",
      "Processing img-1005.jpg (10/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.31\n",
      "F1-score: 0.47\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1005_output.jpg\n",
      "Processing img-1006.jpg (11/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.24\n",
      "F1-score: 0.38\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1006_output.jpg\n",
      "Processing img-1007.jpg (12/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.88\n",
      "F1-score: 0.93\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1007_output.jpg\n",
      "Processing img-1008.jpg (13/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.25\n",
      "F1-score: 0.40\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1008_output.jpg\n",
      "Processing img-1009.jpg (14/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.17\n",
      "F1-score: 0.29\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1009_output.jpg\n",
      "Processing img-101.jpg (15/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-101_output.jpg\n",
      "Processing img-1010.jpg (16/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.17\n",
      "F1-score: 0.29\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1010_output.jpg\n",
      "Processing img-1011.jpg (17/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.50\n",
      "F1-score: 0.67\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1011_output.jpg\n",
      "Processing img-1012.jpg (18/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.60\n",
      "F1-score: 0.75\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1012_output.jpg\n",
      "Processing img-1013.jpg (19/25)\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1013_output.jpg\n",
      "Processing img-1014.jpg (20/25)\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1014_output.jpg\n",
      "Processing img-1015.jpg (21/25)\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1015_output.jpg\n",
      "Processing img-1016.jpg (22/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1016_output.jpg\n",
      "Processing img-1017.jpg (23/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.40\n",
      "F1-score: 0.57\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1017_output.jpg\n",
      "Processing img-1018.jpg (24/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.33\n",
      "F1-score: 0.50\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1018_output.jpg\n",
      "Processing img-1019.jpg (25/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1019_output.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Set logging level to WARNING to reduce output\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load a pretrained YOLO model (make sure \"best.pt\" exists in your working directory)\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# IoU calculation function\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_t, y1_t, x2_t, y2_t = box2\n",
    "    \n",
    "    # Calculate the coordinates of the intersection rectangle\n",
    "    ix1 = max(x1, x1_t)\n",
    "    iy1 = max(y1, y1_t)\n",
    "    ix2 = min(x2, x2_t)\n",
    "    iy2 = min(y2, y2_t)\n",
    "\n",
    "    # Check if there is an intersection\n",
    "    inter_area = max(0, ix2 - ix1) * max(0, iy2 - iy1)\n",
    "    \n",
    "    # Calculate areas\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2_t - x1_t) * (y2_t - y1_t)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area if union_area > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# Function to load ground truth annotations from a text file\n",
    "def load_ground_truth(txt_file, img_width, img_height):\n",
    "    gt_boxes = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            \n",
    "            # Convert normalized coordinates to pixel values\n",
    "            x1 = int((x_center - width / 2) * img_width)\n",
    "            y1 = int((y_center - height / 2) * img_height)\n",
    "            x2 = int((x_center + width / 2) * img_width)\n",
    "            y2 = int((y_center + height / 2) * img_height)\n",
    "            \n",
    "            gt_boxes.append([x1, y1, x2, y2])\n",
    "    return gt_boxes\n",
    "\n",
    "# Function to detect potholes in an image and analyze performance\n",
    "def detect_potholes_and_evaluate(image_path, annotation_path, output_path=\"output_with_detections.jpg\", conf_threshold=0.55):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image from {image_path}. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    # Get image dimensions\n",
    "    img_height, img_width, _ = img.shape\n",
    "    \n",
    "    # Load ground truth annotations from the text file\n",
    "    ground_truth_boxes = load_ground_truth(annotation_path, img_width, img_height)\n",
    "\n",
    "    # Perform inference\n",
    "    results = model(img)\n",
    "    \n",
    "    # Initialize lists for true positives, false positives, false negatives\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    # Define colors for bounding box and text\n",
    "    box_color = (255, 0, 0)  # Blue box\n",
    "    text_color = (255, 255, 255)  # White text\n",
    "\n",
    "    detected_boxes = []\n",
    "\n",
    "    # Process results\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Get bounding boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].numpy().astype(int)  # Get coordinates of bounding box\n",
    "            confidence = box.conf[0].item()  # Get confidence score\n",
    "            \n",
    "            # Filter detections by confidence threshold\n",
    "            if confidence > conf_threshold:\n",
    "                detected_boxes.append([x1, y1, x2, y2])\n",
    "                \n",
    "                # Draw bounding box and label\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)\n",
    "                cv2.putText(img, f'Pothole {confidence:.2f}', (x1, y1 - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 2)\n",
    "    \n",
    "    # Compare detected boxes with ground truth\n",
    "    for gt_box in ground_truth_boxes:\n",
    "        matched = False\n",
    "        for det_box in detected_boxes:\n",
    "            if iou(gt_box, det_box) > 0.5:  # If IoU > 0.5, consider it a match\n",
    "                tp += 1\n",
    "                matched = True\n",
    "                detected_boxes.remove(det_box)\n",
    "                break\n",
    "        if not matched:\n",
    "            fn += 1\n",
    "\n",
    "    # Any remaining detected boxes are false positives\n",
    "    fp += len(detected_boxes)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    total_gt_boxes = len(ground_truth_boxes)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Display the evaluation metrics\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "\n",
    "    # Display the image with detected potholes\n",
    "    cv2.imshow(\"Detected Potholes\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the image with detections\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"Detection results saved to {output_path}\")\n",
    "\n",
    "# Example usage: Process first 25 images and their corresponding annotation files\n",
    "def process_images_from_dataset(dataset_path, output_dir, num_images=25):\n",
    "    # Check if the output directory exists, otherwise create it\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # List all image files in the dataset directory\n",
    "    image_files = [f for f in os.listdir(dataset_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "    # Limit the processing to the first `num_images` images\n",
    "    for i, image_file in enumerate(image_files[:num_images]):\n",
    "        image_path = os.path.join(dataset_path, image_file)\n",
    "        annotation_path = os.path.join(dataset_path, image_file.replace(image_file.split('.')[-1], 'txt'))\n",
    "\n",
    "        if os.path.exists(annotation_path):\n",
    "            print(f\"Processing {image_file} ({i+1}/{num_images})\")\n",
    "            # Extract the image name without the extension\n",
    "            output_image_path = os.path.join(output_dir, f\"{os.path.splitext(image_file)[0]}_output.jpg\")\n",
    "            detect_potholes_and_evaluate(image_path, annotation_path, output_path=output_image_path)\n",
    "        else:\n",
    "            print(f\"Annotation file not found for {image_file}, skipping...\")\n",
    "\n",
    "# Example usage\n",
    "dataset_path = r\"D:\\Myproject\\Pothole Dataset\"  # Path to your dataset folder\n",
    "output_dir = r\"D:\\Myproject\\Pothole Dataset\\outputs\"  # Folder to save output images\n",
    "process_images_from_dataset(dataset_path, output_dir, num_images=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48841774-c1ad-4fbc-8ff5-c3ae8bd00296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation file not found for blackedge.jpg, skipping...\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-10_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-100_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1000_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1001_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1002_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1003_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1004_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1005_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1006_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1007_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1008_output.jpg\n",
      "Overall Precision: 0.93\n",
      "Overall Recall: 0.35\n",
      "Overall F1-score: 0.51\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Set logging level to WARNING to reduce output\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load a pretrained YOLO model (make sure \"best.pt\" exists in your working directory)\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# IoU calculation function\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_t, y1_t, x2_t, y2_t = box2\n",
    "    \n",
    "    # Calculate the coordinates of the intersection rectangle\n",
    "    ix1 = max(x1, x1_t)\n",
    "    iy1 = max(y1, y1_t)\n",
    "    ix2 = min(x2, x2_t)\n",
    "    iy2 = min(y2, y2_t)\n",
    "\n",
    "    # Check if there is an intersection\n",
    "    inter_area = max(0, ix2 - ix1) * max(0, iy2 - iy1)\n",
    "    \n",
    "    # Calculate areas\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2_t - x1_t) * (y2_t - y1_t)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area if union_area > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# Function to load ground truth annotations from a text file\n",
    "def load_ground_truth(txt_file, img_width, img_height):\n",
    "    gt_boxes = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            \n",
    "            # Convert normalized coordinates to pixel values\n",
    "            x1 = int((x_center - width / 2) * img_width)\n",
    "            y1 = int((y_center - height / 2) * img_height)\n",
    "            x2 = int((x_center + width / 2) * img_width)\n",
    "            y2 = int((y_center + height / 2) * img_height)\n",
    "            \n",
    "            gt_boxes.append([x1, y1, x2, y2])\n",
    "    return gt_boxes\n",
    "\n",
    "# Function to process all images and aggregate results\n",
    "def detect_potholes_and_evaluate_all(dataset_path, output_dir, conf_threshold=0.55):\n",
    "    # Initialize overall variables\n",
    "    total_tp, total_fp, total_fn = 0, 0, 0\n",
    "    all_ground_truth_boxes = []\n",
    "    all_detected_boxes = []\n",
    "\n",
    "    # Iterate through the first 25 images in the dataset\n",
    "    for idx, image_name in enumerate(os.listdir(dataset_path)[:25]):\n",
    "        # Skip non-image files\n",
    "        if not image_name.endswith(\".jpg\"):\n",
    "            continue\n",
    "        \n",
    "        image_path = os.path.join(dataset_path, image_name)\n",
    "        annotation_file = os.path.join(dataset_path, image_name.replace(\".jpg\", \".txt\"))\n",
    "        \n",
    "        # Check if annotation file exists\n",
    "        if not os.path.exists(annotation_file):\n",
    "            print(f\"Annotation file not found for {image_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Load image and ground truth annotations\n",
    "        img = cv2.imread(image_path)\n",
    "        img_height, img_width, _ = img.shape\n",
    "        ground_truth_boxes = load_ground_truth(annotation_file, img_width, img_height)\n",
    "        \n",
    "        # Perform inference\n",
    "        results = model(img)\n",
    "        \n",
    "        detected_boxes = []\n",
    "        \n",
    "        # Process results\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].numpy().astype(int)  # Get coordinates of bounding box\n",
    "                confidence = box.conf[0].item()  # Get confidence score\n",
    "                \n",
    "                # Filter detections by confidence threshold\n",
    "                if confidence > conf_threshold:\n",
    "                    detected_boxes.append([x1, y1, x2, y2])\n",
    "                    \n",
    "                    # Draw bounding box and label\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(img, f'Pothole {confidence:.2f}', (x1, y1 - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        # Compare detected boxes with ground truth\n",
    "        for gt_box in ground_truth_boxes:\n",
    "            matched = False\n",
    "            for det_box in detected_boxes:\n",
    "                if iou(gt_box, det_box) > 0.5:  # If IoU > 0.5, consider it a match\n",
    "                    total_tp += 1\n",
    "                    matched = True\n",
    "                    detected_boxes.remove(det_box)\n",
    "                    break\n",
    "            if not matched:\n",
    "                total_fn += 1\n",
    "\n",
    "        # Any remaining detected boxes are false positives\n",
    "        total_fp += len(detected_boxes)\n",
    "\n",
    "        # Save the image with detections\n",
    "        output_path = os.path.join(output_dir, f\"{image_name.replace('.jpg', '_output.jpg')}\")\n",
    "        cv2.imwrite(output_path, img)\n",
    "        print(f\"Detection results saved to {output_path}\")\n",
    "        \n",
    "        # Store ground truth and detected boxes for later metric calculation\n",
    "        all_ground_truth_boxes.extend(ground_truth_boxes)\n",
    "        all_detected_boxes.extend(detected_boxes)\n",
    "\n",
    "    # Calculate overall precision, recall, and F1-score\n",
    "    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "    recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Display overall evaluation metrics\n",
    "    print(f\"Overall Precision: {precision:.2f}\")\n",
    "    print(f\"Overall Recall: {recall:.2f}\")\n",
    "    print(f\"Overall F1-score: {f1:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "dataset_path = r\"D:\\Myproject\\Pothole Dataset\"  # Update with your dataset path\n",
    "output_dir = r\"D:\\Myproject\\Pothole Dataset\\outputs\"  # Update with your desired output folder\n",
    "detect_potholes_and_evaluate_all(dataset_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b58e3644-ee1e-4222-a81c-58ef742568de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing blackedge.jpg (1/25)\n",
      "Annotation file not found: D:\\Myproject\\Pothole Dataset\\blackedge.txt\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\blackedge_output.jpg\n",
      "Processing img-1.jpg (2/25)\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-score: 0.67\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1_output.jpg\n",
      "Processing img-10.jpg (3/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-10_output.jpg\n",
      "Processing img-100.jpg (4/25)\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-score: 0.67\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-100_output.jpg\n",
      "Processing img-1000.jpg (5/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1000_output.jpg\n",
      "Processing img-1001.jpg (6/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.40\n",
      "F1-score: 0.57\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1001_output.jpg\n",
      "Processing img-1002.jpg (7/25)\n",
      "Precision: 0.88\n",
      "Recall: 0.41\n",
      "F1-score: 0.56\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1002_output.jpg\n",
      "Processing img-1003.jpg (8/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.33\n",
      "F1-score: 0.50\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1003_output.jpg\n",
      "Processing img-1004.jpg (9/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1004_output.jpg\n",
      "Processing img-1005.jpg (10/25)\n",
      "Precision: 0.91\n",
      "Recall: 0.77\n",
      "F1-score: 0.83\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1005_output.jpg\n",
      "Processing img-1006.jpg (11/25)\n",
      "Precision: 0.91\n",
      "Recall: 0.59\n",
      "F1-score: 0.71\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1006_output.jpg\n",
      "Processing img-1007.jpg (12/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.88\n",
      "F1-score: 0.93\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1007_output.jpg\n",
      "Processing img-1008.jpg (13/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.25\n",
      "F1-score: 0.40\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1008_output.jpg\n",
      "Processing img-1009.jpg (14/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.17\n",
      "F1-score: 0.29\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1009_output.jpg\n",
      "Processing img-101.jpg (15/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-101_output.jpg\n",
      "Processing img-1010.jpg (16/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.17\n",
      "F1-score: 0.29\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1010_output.jpg\n",
      "Processing img-1011.jpg (17/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.50\n",
      "F1-score: 0.67\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1011_output.jpg\n",
      "Processing img-1012.jpg (18/25)\n",
      "Precision: 0.75\n",
      "Recall: 0.60\n",
      "F1-score: 0.67\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1012_output.jpg\n",
      "Processing img-1013.jpg (19/25)\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1013_output.jpg\n",
      "Processing img-1014.jpg (20/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.12\n",
      "F1-score: 0.22\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1014_output.jpg\n",
      "Processing img-1015.jpg (21/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1015_output.jpg\n",
      "Processing img-1016.jpg (22/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1016_output.jpg\n",
      "Processing img-1017.jpg (23/25)\n",
      "Precision: 0.75\n",
      "Recall: 0.60\n",
      "F1-score: 0.67\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1017_output.jpg\n",
      "Processing img-1018.jpg (24/25)\n",
      "Precision: 1.00\n",
      "Recall: 0.33\n",
      "F1-score: 0.50\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1018_output.jpg\n",
      "Processing img-1019.jpg (25/25)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1019_output.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Set logging level to WARNING to reduce output\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load the pretrained YOLO model (ensure \"best.pt\" exists in your working directory)\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# IoU calculation function\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_t, y1_t, x2_t, y2_t = box2\n",
    "    \n",
    "    # Calculate the coordinates of the intersection rectangle\n",
    "    ix1 = max(x1, x1_t)\n",
    "    iy1 = max(y1, y1_t)\n",
    "    ix2 = min(x2, x2_t)\n",
    "    iy2 = min(y2, y2_t)\n",
    "\n",
    "    # Check if there is an intersection\n",
    "    inter_area = max(0, ix2 - ix1) * max(0, iy2 - iy1)\n",
    "    \n",
    "    # Calculate areas\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2_t - x1_t) * (y2_t - y1_t)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area if union_area > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# Function to load ground truth annotations from a text file\n",
    "def load_ground_truth(txt_file, img_width, img_height):\n",
    "    gt_boxes = []\n",
    "    if not os.path.exists(txt_file):\n",
    "        print(f\"Annotation file not found: {txt_file}\")\n",
    "        return gt_boxes\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            \n",
    "            # Convert normalized coordinates to pixel values\n",
    "            x1 = int((x_center - width / 2) * img_width)\n",
    "            y1 = int((y_center - height / 2) * img_height)\n",
    "            x2 = int((x_center + width / 2) * img_width)\n",
    "            y2 = int((y_center + height / 2) * img_height)\n",
    "            \n",
    "            gt_boxes.append([x1, y1, x2, y2])\n",
    "    return gt_boxes\n",
    "\n",
    "# Function to detect potholes in an image and analyze performance\n",
    "def detect_potholes_and_evaluate(image_path, annotation_path, output_path=\"output_with_detections.jpg\", conf_threshold=0.45, iou_threshold=0.4):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image from {image_path}. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    # Get image dimensions\n",
    "    img_height, img_width, _ = img.shape\n",
    "    \n",
    "    # Load ground truth annotations from the text file\n",
    "    ground_truth_boxes = load_ground_truth(annotation_path, img_width, img_height)\n",
    "\n",
    "    # Perform inference\n",
    "    results = model(img)\n",
    "    \n",
    "    # Initialize lists for true positives, false positives, false negatives\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    # Define colors for bounding box and text\n",
    "    box_color = (255, 0, 0)  # Blue box\n",
    "    text_color = (255, 255, 255)  # White text\n",
    "\n",
    "    detected_boxes = []\n",
    "\n",
    "    # Process results\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Get bounding boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].numpy().astype(int)  # Get coordinates of bounding box\n",
    "            confidence = box.conf[0].item()  # Get confidence score\n",
    "            \n",
    "            # Filter detections by confidence threshold\n",
    "            if confidence > conf_threshold:\n",
    "                detected_boxes.append([x1, y1, x2, y2])\n",
    "                \n",
    "                # Draw bounding box and label\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)\n",
    "                cv2.putText(img, f'Pothole {confidence:.2f}', (x1, y1 - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 2)\n",
    "    \n",
    "    # Compare detected boxes with ground truth\n",
    "    for gt_box in ground_truth_boxes:\n",
    "        matched = False\n",
    "        for det_box in detected_boxes:\n",
    "            if iou(gt_box, det_box) > iou_threshold:  # If IoU > threshold, consider it a match\n",
    "                tp += 1\n",
    "                matched = True\n",
    "                detected_boxes.remove(det_box)\n",
    "                break\n",
    "        if not matched:\n",
    "            fn += 1\n",
    "\n",
    "    # Any remaining detected boxes are false positives\n",
    "    fp += len(detected_boxes)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    total_gt_boxes = len(ground_truth_boxes)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Display the evaluation metrics\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "\n",
    "    # Display the image with detected potholes\n",
    "    cv2.imshow(\"Detected Potholes\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the image with detections\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"Detection results saved to {output_path}\")\n",
    "\n",
    "# Function to process the first 25 images and evaluate\n",
    "def process_dataset(dataset_path, output_dir, num_images=25, conf_threshold=0.45, iou_threshold=0.4):\n",
    "    images = sorted([f for f in os.listdir(dataset_path) if f.endswith('.jpg')])[:num_images]\n",
    "    for i, img_name in enumerate(images, start=1):\n",
    "        image_path = os.path.join(dataset_path, img_name)\n",
    "        annotation_path = os.path.join(dataset_path, img_name.replace('.jpg', '.txt'))\n",
    "        output_path = os.path.join(output_dir, f\"{img_name.replace('.jpg', '')}_output.jpg\")\n",
    "        \n",
    "        print(f\"Processing {img_name} ({i}/{num_images})\")\n",
    "        detect_potholes_and_evaluate(image_path, annotation_path, output_path, conf_threshold, iou_threshold)\n",
    "\n",
    "# Example usage\n",
    "dataset_path = r\"D:\\Myproject\\Pothole Dataset\"  # Update with your dataset path\n",
    "output_dir = r\"D:\\Myproject\\Pothole Dataset\\outputs\"  # Update with your output folder\n",
    "process_dataset(dataset_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56b45577-ed93-410f-96b4-30ef12165bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation file not found for blackedge.jpg, skipping...\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-10_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-100_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1000_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1001_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1002_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1003_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1004_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1005_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1006_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1007_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1008_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1009_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-101_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1010_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1011_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1012_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1013_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1014_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1015_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1016_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1017_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1018_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1019_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-102_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1020_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1021_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1022_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1023_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1024_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1025_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1026_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1027_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1028_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1029_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-103_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1030_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1031_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1032_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1033_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1034_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1035_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1036_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1037_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1038_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1039_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-104_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1040_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Pothole Dataset\\outputs\\img-1041_output.jpg\n",
      "Overall Precision: 0.94\n",
      "Overall Recall: 0.38\n",
      "Overall F1-score: 0.54\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Set logging level to WARNING to reduce output\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load a pretrained YOLO model (make sure \"best.pt\" exists in your working directory)\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# IoU calculation function\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_t, y1_t, x2_t, y2_t = box2\n",
    "    \n",
    "    # Calculate the coordinates of the intersection rectangle\n",
    "    ix1 = max(x1, x1_t)\n",
    "    iy1 = max(y1, y1_t)\n",
    "    ix2 = min(x2, x2_t)\n",
    "    iy2 = min(y2, y2_t)\n",
    "\n",
    "    # Check if there is an intersection\n",
    "    inter_area = max(0, ix2 - ix1) * max(0, iy2 - iy1)\n",
    "    \n",
    "    # Calculate areas\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2_t - x1_t) * (y2_t - y1_t)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area if union_area > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# Function to load ground truth annotations from a text file\n",
    "def load_ground_truth(txt_file, img_width, img_height):\n",
    "    gt_boxes = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            \n",
    "            # Convert normalized coordinates to pixel values\n",
    "            x1 = int((x_center - width / 2) * img_width)\n",
    "            y1 = int((y_center - height / 2) * img_height)\n",
    "            x2 = int((x_center + width / 2) * img_width)\n",
    "            y2 = int((y_center + height / 2) * img_height)\n",
    "            \n",
    "            gt_boxes.append([x1, y1, x2, y2])\n",
    "    return gt_boxes\n",
    "\n",
    "# Function to process all images and aggregate results\n",
    "def detect_potholes_and_evaluate_all(dataset_path, output_dir, conf_threshold=0.55):\n",
    "    # Initialize overall variables\n",
    "    total_tp, total_fp, total_fn = 0, 0, 0\n",
    "    all_ground_truth_boxes = []\n",
    "    all_detected_boxes = []\n",
    "\n",
    "    # Iterate through the first 100 images in the dataset\n",
    "    for idx, image_name in enumerate(os.listdir(dataset_path)[:100]):  # Changed from [:25] to [:100]\n",
    "        # Skip non-image files\n",
    "        if not image_name.endswith(\".jpg\"):\n",
    "            continue\n",
    "        \n",
    "        image_path = os.path.join(dataset_path, image_name)\n",
    "        annotation_file = os.path.join(dataset_path, image_name.replace(\".jpg\", \".txt\"))\n",
    "        \n",
    "        # Check if annotation file exists\n",
    "        if not os.path.exists(annotation_file):\n",
    "            print(f\"Annotation file not found for {image_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Load image and ground truth annotations\n",
    "        img = cv2.imread(image_path)\n",
    "        img_height, img_width, _ = img.shape\n",
    "        ground_truth_boxes = load_ground_truth(annotation_file, img_width, img_height)\n",
    "        \n",
    "        # Perform inference\n",
    "        results = model(img)\n",
    "        \n",
    "        detected_boxes = []\n",
    "        \n",
    "        # Process results\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].numpy().astype(int)  # Get coordinates of bounding box\n",
    "                confidence = box.conf[0].item()  # Get confidence score\n",
    "                \n",
    "                # Filter detections by confidence threshold\n",
    "                if confidence > conf_threshold:\n",
    "                    detected_boxes.append([x1, y1, x2, y2])\n",
    "                    \n",
    "                    # Draw bounding box and label\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(img, f'Pothole {confidence:.2f}', (x1, y1 - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        # Compare detected boxes with ground truth\n",
    "        for gt_box in ground_truth_boxes:\n",
    "            matched = False\n",
    "            for det_box in detected_boxes:\n",
    "                if iou(gt_box, det_box) > 0.5:  # If IoU > 0.5, consider it a match\n",
    "                    total_tp += 1\n",
    "                    matched = True\n",
    "                    detected_boxes.remove(det_box)\n",
    "                    break\n",
    "            if not matched:\n",
    "                total_fn += 1\n",
    "\n",
    "        # Any remaining detected boxes are false positives\n",
    "        total_fp += len(detected_boxes)\n",
    "\n",
    "        # Save the image with detections\n",
    "        output_path = os.path.join(output_dir, f\"{image_name.replace('.jpg', '_output.jpg')}\")\n",
    "        cv2.imwrite(output_path, img)\n",
    "        print(f\"Detection results saved to {output_path}\")\n",
    "        \n",
    "        # Store ground truth and detected boxes for later metric calculation\n",
    "        all_ground_truth_boxes.extend(ground_truth_boxes)\n",
    "        all_detected_boxes.extend(detected_boxes)\n",
    "\n",
    "    # Calculate overall precision, recall, and F1-score\n",
    "    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "    recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Display overall evaluation metrics\n",
    "    print(f\"Overall Precision: {precision:.2f}\")\n",
    "    print(f\"Overall Recall: {recall:.2f}\")\n",
    "    print(f\"Overall F1-score: {f1:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "dataset_path = r\"D:\\Myproject\\Pothole Dataset\"  # Update with your dataset path\n",
    "output_dir = r\"D:\\Myproject\\Pothole Dataset\\outputs\"  # Update with your desired output folder\n",
    "detect_potholes_and_evaluate_all(dataset_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e780b14-8d22-44d8-8176-1cc7999ac117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched! IoU: 0.96\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-440_output.jpg\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-441_output.jpg\n",
      "Matched! IoU: 0.89\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-442_output.jpg\n",
      "Matched! IoU: 0.95\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-443_output.jpg\n",
      "Matched! IoU: 0.64\n",
      "Matched! IoU: 0.87\n",
      "Matched! IoU: 0.84\n",
      "Matched! IoU: 0.83\n",
      "Matched! IoU: 0.95\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-444_output.jpg\n",
      "Matched! IoU: 0.88\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-445_output.jpg\n",
      "Matched! IoU: 0.88\n",
      "Matched! IoU: 0.72\n",
      "Matched! IoU: 0.87\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-446_output.jpg\n",
      "Matched! IoU: 0.87\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-447_output.jpg\n",
      "Matched! IoU: 0.83\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-448_output.jpg\n",
      "Matched! IoU: 0.92\n",
      "Matched! IoU: 0.83\n",
      "Matched! IoU: 0.90\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-449_output.jpg\n",
      "Matched! IoU: 0.92\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-450_output.jpg\n",
      "Matched! IoU: 0.84\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-451_output.jpg\n",
      "Matched! IoU: 0.93\n",
      "Detection results saved to D:\\Myproject\\Final_dataset\\outputs\\img-452_output.jpg\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Overall Accuracy: 0.48\n",
      "Overall Precision: 0.95\n",
      "Overall Recall: 0.49\n",
      "Overall F1-score: 0.65\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Set logging level to WARNING to reduce output\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load a pretrained YOLO model (make sure \"best.pt\" exists in your working directory)\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# IoU calculation function\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_t, y1_t, x2_t, y2_t = box2\n",
    "    \n",
    "    # Calculate the coordinates of the intersection rectangle\n",
    "    ix1 = max(x1, x1_t)\n",
    "    iy1 = max(y1, y1_t)\n",
    "    ix2 = min(x2, x2_t)\n",
    "    iy2 = min(y2, y2_t)\n",
    "\n",
    "    # Check if there is an intersection\n",
    "    inter_area = max(0, ix2 - ix1) * max(0, iy2 - iy1)\n",
    "    \n",
    "    # Calculate areas\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2_t - x1_t) * (y2_t - y1_t)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# Function to load ground truth annotations from a text file\n",
    "def load_ground_truth(txt_file, img_width, img_height):\n",
    "    gt_boxes = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            \n",
    "            # Convert normalized coordinates to pixel values\n",
    "            x1 = int((x_center - width / 2) * img_width)\n",
    "            y1 = int((y_center - height / 2) * img_height)\n",
    "            x2 = int((x_center + width / 2) * img_width)\n",
    "            y2 = int((y_center + height / 2) * img_height)\n",
    "            \n",
    "            gt_boxes.append([x1, y1, x2, y2])\n",
    "    return gt_boxes\n",
    "\n",
    "# Function to process all images and aggregate results\n",
    "def detect_potholes_and_evaluate_all(dataset_path, output_dir, conf_threshold=0.55):\n",
    "    # Initialize overall variables\n",
    "    total_tp, total_fp, total_fn = 0, 0, 0\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate through the first 25 images in the dataset\n",
    "    for idx, image_name in enumerate(os.listdir(dataset_path)[:25]):\n",
    "        # Skip non-image files\n",
    "        if not image_name.endswith(\".jpg\"):\n",
    "            continue\n",
    "        \n",
    "        image_path = os.path.join(dataset_path, image_name)\n",
    "        annotation_file = os.path.join(dataset_path, image_name.replace(\".jpg\", \".txt\"))\n",
    "        \n",
    "        # Check if annotation file exists\n",
    "        if not os.path.exists(annotation_file):\n",
    "            print(f\"Annotation file not found for {image_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Load image and ground truth annotations\n",
    "        img = cv2.imread(image_path)\n",
    "        img_height, img_width, _ = img.shape\n",
    "        ground_truth_boxes = load_ground_truth(annotation_file, img_width, img_height)\n",
    "        \n",
    "        # Perform inference\n",
    "        results = model(img)\n",
    "        \n",
    "        detected_boxes = []\n",
    "        \n",
    "        # Process results\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].numpy().astype(int)  # Get coordinates of bounding box\n",
    "                confidence = box.conf[0].item()  # Get confidence score\n",
    "                \n",
    "                # Filter detections by confidence threshold\n",
    "                if confidence > conf_threshold:\n",
    "                    detected_boxes.append([x1, y1, x2, y2])\n",
    "                    \n",
    "                    # Draw bounding box and label\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(img, f'Pothole {confidence:.2f}', (x1, y1 - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        # Compare detected boxes with ground truth\n",
    "        for gt_box in ground_truth_boxes:\n",
    "            matched = False\n",
    "            for det_box in detected_boxes:\n",
    "                current_iou = iou(gt_box, det_box)  # Calculate IoU\n",
    "                if current_iou > 0.5:  # If IoU > 0.5, consider it a match\n",
    "                    print(f\"Matched! IoU: {current_iou:.2f}\")\n",
    "                    total_tp += 1\n",
    "                    matched = True\n",
    "                    detected_boxes.remove(det_box)\n",
    "                    break\n",
    "            if not matched:\n",
    "                total_fn += 1\n",
    "\n",
    "        # Any remaining detected boxes are false positives\n",
    "        total_fp += len(detected_boxes)\n",
    "\n",
    "        # Save the image with detections\n",
    "        output_path = os.path.join(output_dir, f\"{image_name.replace('.jpg', '_output.jpg')}\")\n",
    "        cv2.imwrite(output_path, img)\n",
    "        print(f\"Detection results saved to {output_path}\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = total_tp / (total_tp + total_fp + total_fn) if (total_tp + total_fp + total_fn) > 0 else 0\n",
    "    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "    recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Display overall evaluation metrics\n",
    "    print(\"\\n--- Evaluation Results ---\")\n",
    "    print(f\"Overall Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Overall Precision: {precision:.2f}\")\n",
    "    print(f\"Overall Recall: {recall:.2f}\")\n",
    "    print(f\"Overall F1-score: {f1:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = r\"D:\\Myproject\\Final_dataset\"  # Update with your dataset path\n",
    "    output_dir = r\"D:\\Myproject\\Final_dataset\\outputs\"  # Update with your desired output folder\n",
    "    detect_potholes_and_evaluate_all(dataset_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ed2abd-0e37-4d4b-a97e-152644b3fd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
